### MISC
   # port of recording server
port=6666
   # identifier for label-lines in annotation file
labelIdentifier=LABELS
   # identifier for transcription-lines in annotation file
transcriptIdentifier=TRANSCRIPTION
   # identifier for transcription-lines in annotation file
recognitionIdentifier=RECOGNIZED
   # identifier for prediction-lines in annotation file
predictionIdentifier=PREDICTION
   # identifier for originators in annotation file 
originatorIdentifier=ORIGINATOR
   # extension for audio-accompanying annotation file 
labelFileExtension=txt
   # extension of audio files (others will be disregarded)
audioFormat=wav
   # more debug output @see logConfig.xml
garrulous=false
   # sample rate of audio files
sampleRate=16000
   # feature extraction method
usePraat=false
useOpenEar=true
   # default type for EmotionML
defaultEmotionType=category
   # default name for EmotionML
defaultEmotionName=angry
   # default value for confidence
defaultConfidence=1
   # classification method
useWEKA=true
   # default name for annotator
defaultUser=human
   # default id for emotionml vocabulary
defaultVocabId=mycats
   # whether feature extraction before model building starts from scratch
   # or extracts only files that have no prediction yet.
additiveTraining=false
   # label to category mapping: pairs of category descriptors 
   # assigned to minimum labels, e.g. 1,N;2,NA means category "N" 
   # is assigned for values between 1>=x<2.
   # MUST be in ascending order!
categories=-1,NA;0,G;1,N;2,L;3,A;4,A;5,A
#categories=-1,NA;0,G;0.2,N;0.4,L;0.6,A;0.8,A;1,A
  # categories=-1,NA;1,N;3,A
#categories=-1,NA;1,c;2,yf;3,ym;4,af;5,am;6,sf;7,sm
# categories=-1,1;2,2;3,3;4,4;5,5;6,6;7,7
   # whether to use EmotionML for import, export and storage
emotionmlMode=false
   # the default set for the emotionml vocbulary sets
emotionml-category-set-default=http://www.w3.org/TR/emotion-voc/#everyday-categories
emotionml-dimension-set-default=http://www.w3.org/TR/emotion-voc/#pad-dimensions
emotionml-appraisal-set-default=http://www.w3.org/TR/emotion-voc/#occ-appraisals
emotionml-action-tendency-set-default=http://www.w3.org/TR/emotion-voc/#frijda-action-tendencies
emotion.label.cat=cat
emotion.label.val=val
emotion.label.type=type
emotion.label.name=name
emotion.label.vocabId=vocabId
emotion.label.conf=conf
emotion.label.orig=orig
   # character encoding, e.g. ISO8859-1 or UTF-8
charEnc=ISO8859-1
# charEnc=UTF-8
   # command to execute on selected audiofiles
execCmd=mplayer
   # whether to use the spellchecker
withSpellChecker=false
#### PATHES
ttsRulesFile=res/ttsFilterRules.txt
ttsVocabFile=res/ttsFilterVocab.txt
normalizeRules=res/normalizeRules.txt
normalizeVocab=res/normalizeVocab.txt
emlUrl=http://192.168.188.129:8080/EMLQueue/Transcribe
recognitionTmpDir=C:/temp/
recordingDir=recordings
hypothesisFile=hypothesis.txt
referenceFile=references.txt
resultFile=results.txt
scliteTool=tools/sclite.exe
tempFeatFile=tmp/tmpFeat.txt
praatCommand=./tools/praatcon.exe
praatScriptFile=res/extractFeatures.praat
trainFile=res/train.arff
testFile=res/test.arff
arffHeaderFile=res/ARFFHeader.txt
logConfig=logConfig.xml
   # classifier type, smo, j48 or naiveBayes
classifier=smo
modelFile=res/myDemoAngerLive.model
#modelFile=res/classifier_home.model
#modelFile=res/angerBackup.model
#modelFile=res/classifier.model
#modelFile=res/classifier_LayEmoDB.model
#modelFile=res/classifier.model
#modelFile=res/agenderAllIS10.model
openEarCommand=./tools/os2.1/SMILExtract_ReleasePortaudio.exe
#openEarConfig=tools/os2.1/config/IS09_emotion.conf
#openEarCommand=./tools/SMILExtract.exe
openEarConfig=res/IS10.anger_functs.conf
#openEarConfig=res/IS10.anger_functs.conf
openEarConfigAgenderIS10=res/IS10.agender_functs.conf
openEarConfigIS09=res/emo_IS09.conf
openEarConfigLarge=res/emobase.conf
#useTTS=emofilt|svox|ivona|mary
useTTS=mary
mbrola=tools/mbrola/mbrola
txt2pho=c:/Programme/Txt2pho/txt2pho.exe /G=
tmpTxtFile=tmp/tmp.txt
tmpWavFile=tmp/tmp.wav
tmpPhoFile=tmp/tmp.pho
tmpPhoEmotionFile=tmp/tmpE.pho
mbrolaDB=tools/Mbrola/voices/
mbrolaVoices=de6,male
# mbrolaVoices=de1,female;de2,male;de3,female;de4,male;de6,male;de7,female
emofilt=java -jar tools/emofilt/emofilt_fat.jar
emofiltDB=-cf tools/emofilt/emofiltConfig.ini
emotions=happiness
# emotions=boredom yawning despair happiness sadness joy fear hotAnger neutral
wavGenOutPrefix=
formatOption=
svoxzh-CNfemale=svox-dz0co0zh-CN22.pil
ttsSexFemale=true
ttsLang=de-DE
svoxde-DEfemale= svox-gl0co0de-DE22.pil
svoxde-DEmale=svox-ag5co0de-DE22.pil
svoxen-USfemale=svox-lh0co0en-US22.pil
svoxen-USmale=svox-mh5co0en-US22.pil
svoxCmd=d:/tts/Svox/svox_431/svox.exe -d d:/tts/Svox/svox_431/ -f
mixFile=res/streetnoise16kHz.raw
mixFactor=0.5
mixExtension=_mix
ivonaCmd=ivonacl -f
ivonaVoice=hans
